{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2',\n",
      "       'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
      "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
      "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
      "       'default.payment.next.month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=\"pastel\")\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "\n",
    "def stdscaler(df):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df)\n",
    "    scX_df = scaler.transform(df)\n",
    "    df=pd.DataFrame(scX_df, index =df.index,columns =df.columns  )\n",
    "    return df\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "samplechoice = \"NearMiss\"\n",
    "\"\"\"\n",
    "if samplechoice == \"SMOTE\":\n",
    "    smt = SMOTE()\n",
    "    train_data , train_y = smt.fit_sample(train_data , train_y)\n",
    "elif samplechoice == \"NearMiss\":\n",
    "    nr = NearMiss()\n",
    "    train_data , train_y = nr.fit_sample(train_data , train_y)\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def kfoldtest(kfoldn,model,Xtrain_df,ytrain_df):\n",
    "    kf=StratifiedKFold(n_splits=kfoldn)\n",
    "    accu=[]\n",
    "    auc=[]\n",
    "    f1 =[]\n",
    "    aab =[]\n",
    "    dcd = []\n",
    "    tim = []\n",
    "    kf.get_n_splits(Xtrain_df,ytrain_df)\n",
    "    \n",
    "    for train_index, test_index in kf.split(Xtrain_df,ytrain_df):\n",
    "        #print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "        t1 =time.time()\n",
    "        X_train, X_test = Xtrain_df.iloc[train_index], Xtrain_df.iloc[test_index]\n",
    "        y_train, y_test = ytrain_df.iloc[train_index], ytrain_df.iloc[test_index]\n",
    "        \n",
    "        \n",
    "        if samplechoice == \"SMOTE\":\n",
    "            smt = SMOTE()\n",
    "            X_train,  y_train = smt.fit_sample(X_train , y_train)\n",
    "        elif samplechoice == \"NearMiss\":\n",
    "            nr = NearMiss()\n",
    "            X_train,  y_train = nr.fit_sample(X_train , y_train)\n",
    "            \n",
    "    \n",
    "        model.fit(X_train,y_train)\n",
    "        try:\n",
    "            accu.append(model.score(X_test,y_test))\n",
    "        except:\n",
    "            print(\"This model have no build-in score.\")\n",
    "            \n",
    "        auc.append(roc_auc_score(y_test,model.predict(X_test)))\n",
    "        f1.append(f1_score(y_test, model.predict(X_test).astype(int),average='binary'))\n",
    "        tim.append(time.time()-t1)\n",
    "        cm1=confusion_matrix(test_y, clf.predict(test_data),labels = [1,0])\n",
    "        sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "        aab.append(sensitivity1)\n",
    "\n",
    "        specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "        dcd.append(specificity1)\n",
    "    return accu,auc,f1,aab,dcd,tim\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "file_name = 'UCI_Credit_Card 2.csv'\n",
    "data =pd.read_csv(file_name,index_col = 0)\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = data[data[\"default.payment.next.month\"]==1].copy()\n",
    "v0 = data[data[\"default.payment.next.month\"]==0].copy()\n",
    "v1.rename(columns={\"default.payment.next.month\": \"default\"},inplace = True)\n",
    "v0.rename(columns={\"default.payment.next.month\": \"default\"},inplace = True)\n",
    "y1 = v1[\"default\"].copy()\n",
    "x1 = v1.copy()\n",
    "del x1[\"default\"]\n",
    "y0 = v0[\"default\"].copy()\n",
    "x0 = v0.copy()\n",
    "del x0[\"default\"]\n",
    "\n",
    "tr1,te1,try1,tey1 = train_test_split(\n",
    "    x1, y1, test_size=0.20, random_state=42)\n",
    "tr2,te2,try2,tey2 = train_test_split(\n",
    "    x0, y0, test_size=0.20, random_state=42)\n",
    "####\n",
    "#tr2=tr2.sample(len(tr1.index))\n",
    "\n",
    "#try2 = try2.loc[tr2.index].copy()\n",
    "####\n",
    "\n",
    "\n",
    "train_data=pd.concat([tr1,tr2],axis=0)\n",
    "\n",
    "train_y = pd.concat([try1,try2],axis=0)\n",
    "test_data=pd.concat([te1,te2],axis=0)\n",
    "\n",
    "test_y = pd.concat([tey1,tey2],axis=0)\n",
    "\n",
    "\n",
    "train_data = stdscaler(train_data )\n",
    "test_data = stdscaler(test_data )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pca =PCA(n_components=.99).fit(train_data)\\ntrain_data = pd.DataFrame(pca.transform(train_data),index = train_data.index)   \\n\\ntest_data= pd.DataFrame(pca.transform(test_data),index = test_data.index)  \\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"pca =PCA(n_components=.99).fit(train_data)\n",
    "train_data = pd.DataFrame(pca.transform(train_data),index = train_data.index)   \n",
    "\n",
    "test_data= pd.DataFrame(pca.transform(test_data),index = test_data.index)  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "\n",
    "clf=LogisticRegression(tol=0.01, C=0.1,solver='lbfgs', max_iter=10000,)\n",
    "accu,auc,f1,aab,dcd,tim =kfoldtest(5,clf,train_data,train_y)\n",
    "result.append(pd.DataFrame([[\"LogisticRegression\",np.average(accu),np.average(auc),\n",
    "                       np.average(f1),np.average(aab),np.average(dcd),np.average(tim)]],\n",
    "                     columns=[\"model names\",'CVaccuracy','CVaucroc','CVF1',\"CVsensitivity\",'CVspecificity','CVtime(s)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=10,class_weight=\"balanced\",random_state=0)\n",
    "accu,auc,f1,aab,dcd,tim =kfoldtest(5,clf,train_data,train_y)\n",
    "result.append(pd.DataFrame([[\"DecisionTree\",np.average(accu),np.average(auc),\n",
    "                       np.average(f1),np.average(aab),np.average(dcd),np.average(tim)]],\n",
    "                     columns=[\"model names\",'CVaccuracy','CVaucroc','CVF1',\"CVsensitivity\",'CVspecificity','CVtime(s)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB(priors=None, var_smoothing=1e-09)\n",
    "accu,auc,f1,aab,dcd,tim =kfoldtest(5,clf,train_data,train_y)\n",
    "result.append(pd.DataFrame([[\"Naive bayes\",np.average(accu),np.average(auc),\n",
    "                       np.average(f1),np.average(aab),np.average(dcd),np.average(tim)]],\n",
    "                     columns=[\"model names\",'CVaccuracy','CVaucroc','CVF1',\"CVsensitivity\",'CVspecificity','CVtime(s)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "                       max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
    "                       warm_start=False)\n",
    "\n",
    "accu,auc,f1,aab,dcd,tim=kfoldtest(5,clf,train_data,train_y)\n",
    "result.append(pd.DataFrame([[\"RandomForest\",np.average(accu),np.average(auc),\n",
    "                       np.average(f1),np.average(aab),np.average(dcd),np.average(tim)]],\n",
    "                     columns=[\"model names\",'CVaccuracy','CVaucroc','CVF1',\"CVsensitivity\",'CVspecificity','CVtime(s)']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=MLPClassifier(activation='tanh', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
    "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "              hidden_layer_sizes=(50, 100, 50), learning_rate='adaptive',\n",
    "              learning_rate_init=0.001, max_iter=3000, momentum=0.9,\n",
    "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "              random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
    "              validation_fraction=0.1, verbose=False, warm_start=False)\n",
    "\n",
    "accu,auc,f1,aab,dcd,tim =kfoldtest(5,clf,train_data,train_y)\n",
    "result.append(pd.DataFrame([[\"MLP\",np.average(accu),np.average(auc),\n",
    "                       np.average(f1),np.average(aab),np.average(dcd),np.average(tim)]],\n",
    "                     columns=[\"model names\",'CVaccuracy','CVaucroc','CVF1',\"CVsensitivity\",'CVspecificity','CVtime(s)']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(algorithm='SAMME.R',\n",
    "                   base_estimator=DecisionTreeClassifier(class_weight='balanced',\n",
    "                                                         criterion='gini',\n",
    "                                                         max_depth=None,\n",
    "                                                         max_features='auto',\n",
    "                                                         max_leaf_nodes=None,\n",
    "                                                         min_impurity_decrease=0.0,\n",
    "                                                         min_impurity_split=None,\n",
    "                                                         min_samples_leaf=1,\n",
    "                                                         min_samples_split=2,\n",
    "                                                         min_weight_fraction_leaf=0.0,\n",
    "                                                         \n",
    "                                                         random_state=0,\n",
    "                                                         splitter='random'),\n",
    "                   learning_rate=1.0, n_estimators=20, random_state=None)\n",
    "\n",
    "accu,auc,f1,aab,dcd,tim =kfoldtest(5,clf,train_data,train_y)\n",
    "result.append(pd.DataFrame([[\"AdaboostDecisionTree\",np.average(accu),np.average(auc),\n",
    "                       np.average(f1),np.average(aab),np.average(dcd),np.average(tim)]],\n",
    "                     columns=[\"model names\",'CVaccuracy','CVaucroc','CVF1',\"CVsensitivity\",'CVspecificity','CVtime(s)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "                           learning_rate=0.15, loss='deviance', max_depth=8,\n",
    "                           max_features='sqrt', max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=0.1, min_samples_split=0.1,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=10,\n",
    "                           n_iter_no_change=None,\n",
    "                           random_state=None, subsample=1.0, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0,\n",
    "                           warm_start=False)\n",
    "accu,auc,f1,aab,dcd ,tim=kfoldtest(5,clf,train_data,train_y)\n",
    "result.append(pd.DataFrame([[\"GradientBoosting\",np.average(accu),np.average(auc),\n",
    "                       np.average(f1),np.average(aab),np.average(dcd),np.average(tim)]],\n",
    "                     columns=[\"model names\",'CVaccuracy','CVaucroc','CVF1',\"CVsensitivity\",'CVspecificity','CVtime(s)']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= pd.concat(result,axis=0)\n",
    "result.to_csv('OGmodel_{}sampling.csv'.format(str(samplechoice)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model names</th>\n",
       "      <th>CVaccuracy</th>\n",
       "      <th>CVaucroc</th>\n",
       "      <th>CVF1</th>\n",
       "      <th>CVsensitivity</th>\n",
       "      <th>CVspecificity</th>\n",
       "      <th>CVtime(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.502896</td>\n",
       "      <td>0.559931</td>\n",
       "      <td>0.370781</td>\n",
       "      <td>0.652711</td>\n",
       "      <td>0.437706</td>\n",
       "      <td>1.473500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.559567</td>\n",
       "      <td>0.605551</td>\n",
       "      <td>0.409005</td>\n",
       "      <td>0.596837</td>\n",
       "      <td>0.599401</td>\n",
       "      <td>1.513342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Naive bayes</td>\n",
       "      <td>0.534814</td>\n",
       "      <td>0.473588</td>\n",
       "      <td>0.256954</td>\n",
       "      <td>0.339006</td>\n",
       "      <td>0.585020</td>\n",
       "      <td>1.458550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.530523</td>\n",
       "      <td>0.606467</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>0.687651</td>\n",
       "      <td>0.515643</td>\n",
       "      <td>7.154964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.467228</td>\n",
       "      <td>0.578580</td>\n",
       "      <td>0.392527</td>\n",
       "      <td>0.762801</td>\n",
       "      <td>0.381982</td>\n",
       "      <td>24.397267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AdaboostDecisionTree</td>\n",
       "      <td>0.484520</td>\n",
       "      <td>0.579897</td>\n",
       "      <td>0.391921</td>\n",
       "      <td>0.715361</td>\n",
       "      <td>0.424395</td>\n",
       "      <td>1.637433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.605360</td>\n",
       "      <td>0.632253</td>\n",
       "      <td>0.433233</td>\n",
       "      <td>0.609639</td>\n",
       "      <td>0.617804</td>\n",
       "      <td>1.517049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model names  CVaccuracy  CVaucroc      CVF1  CVsensitivity  \\\n",
       "0    LogisticRegression    0.502896  0.559931  0.370781       0.652711   \n",
       "0          DecisionTree    0.559567  0.605551  0.409005       0.596837   \n",
       "0           Naive bayes    0.534814  0.473588  0.256954       0.339006   \n",
       "0          RandomForest    0.530523  0.606467  0.411733       0.687651   \n",
       "0                   MLP    0.467228  0.578580  0.392527       0.762801   \n",
       "0  AdaboostDecisionTree    0.484520  0.579897  0.391921       0.715361   \n",
       "0      GradientBoosting    0.605360  0.632253  0.433233       0.609639   \n",
       "\n",
       "   CVspecificity  CVtime(s)  \n",
       "0       0.437706   1.473500  \n",
       "0       0.599401   1.513342  \n",
       "0       0.585020   1.458550  \n",
       "0       0.515643   7.154964  \n",
       "0       0.381982  24.397267  \n",
       "0       0.424395   1.637433  \n",
       "0       0.617804   1.517049  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
