{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns;\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "def stdscaler(df):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df)\n",
    "    scX_df = scaler.transform(df)\n",
    "    df=pd.DataFrame(scX_df, index =df.index,columns =df.columns  )\n",
    "    return df\n",
    "def kfoldtest(kfoldn,model,Xtrain_df,ytrain_df):\n",
    "    kf=StratifiedKFold(n_splits=kfoldn)\n",
    "    accu=[]\n",
    "    auc=[]\n",
    "    f1 =[]\n",
    "    aab =[]\n",
    "    dcd = []\n",
    "    tim = []\n",
    "    kf.get_n_splits(Xtrain_df,ytrain_df)\n",
    "    \n",
    "    for train_index, test_index in kf.split(Xtrain_df,ytrain_df):\n",
    "        #print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "        t1 =time.time()\n",
    "        X_train, X_test = Xtrain_df.iloc[train_index], Xtrain_df.iloc[test_index]\n",
    "        y_train, y_test = ytrain_df.iloc[train_index], ytrain_df.iloc[test_index]\n",
    "        \n",
    "        \"\"\"\n",
    "        if samplechoice == \"SMOTE\":\n",
    "            smt = SMOTE()\n",
    "            X_train,  y_train = smt.fit_sample(X_train , y_train)\n",
    "        elif samplechoice == \"NearMiss\":\n",
    "            nr = NearMiss()\n",
    "            X_train,  y_train = nr.fit_sample(X_train , y_train)\n",
    "        \"\"\"    \n",
    "    \n",
    "        model.fit(X_train,y_train)\n",
    "        try:\n",
    "            accu.append(model.score(X_test,y_test))\n",
    "        except:\n",
    "            print(\"This model have no build-in score.\")\n",
    "            \n",
    "        auc.append(roc_auc_score(y_test,model.predict_proba(X_test)[:,1]))\n",
    "        f1.append(f1_score(y_test, model.predict(X_test).astype(int)))\n",
    "        tim.append(time.time()-t1)\n",
    "        cm1=confusion_matrix(test_y, clf.predict(test_data),labels = [1,0])\n",
    "        print(\"cv result:\")\n",
    "        print(cm1)\n",
    "        sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "        aab.append(sensitivity1)\n",
    "\n",
    "        specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "        dcd.append(specificity1)\n",
    "    return accu,auc,f1,aab,dcd,tim\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'creditcard 2.csv'\n",
    "data =pd.read_csv(file_name)\n",
    "del data['Time']\n",
    "u=StandardScaler().fit_transform(np.array(data['Amount']).reshape(-1,1))\n",
    "data['Amount']=pd.Series(u[:,0],index =data.index)\n",
    "train_y = data['Class'].copy()\n",
    "train_data =data.drop(columns='Class')\n",
    "\n",
    "train_data,test_data,train_y,test_y = train_test_split(\n",
    "    train_data, train_y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplechoice = \"NearMiss\"\n",
    "\n",
    "if samplechoice == \"SMOTE\":\n",
    "    smp = SMOTE()\n",
    "\n",
    "elif samplechoice == \"NearMiss\":\n",
    "    smp = NearMiss()\n",
    "else:\n",
    "    smp=None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_holder = []\n",
    "cvresult_holder = []\n",
    "testroc_holder = []\n",
    "testlabel_holder =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv result:\n",
      "[[   79    19]\n",
      " [  181 56683]]\n",
      "cv result:\n",
      "[[   78    20]\n",
      " [   54 56810]]\n",
      "cv result:\n",
      "[[   79    19]\n",
      " [   96 56768]]\n",
      "cv result:\n",
      "[[   78    20]\n",
      " [   97 56767]]\n",
      "cv result:\n",
      "[[   79    19]\n",
      " [  116 56748]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "param_grid  = { \"lr__C\":np.logspace(-3,3,7),\n",
    "               \"lr__penalty\":[None,\"l2\"],\n",
    "               'lr__class_weight':[None,'balanced']\n",
    "               \n",
    "               \n",
    "                }\n",
    "\n",
    "model = Pipeline([\n",
    "        ('sampling', smp),\n",
    "        ('lr', LogisticRegression(max_iter=3000))\n",
    "    ])\n",
    "\n",
    "\n",
    "clf = GridSearchCV(model, param_grid, cv = 5, scoring = 'roc_auc',n_jobs=-1)\n",
    "clf.fit(train_data,train_y)\n",
    "\n",
    "bestfit =clf.best_estimator_\n",
    "model_holder.append(bestfit)\n",
    "\"\"\"cv\"\"\"\n",
    "accu,auc,f1,aab,dcd,tim =kfoldtest(5,bestfit,train_data,train_y)\n",
    "cvresult_holder.append(pd.DataFrame([[\"LogisticRegression\",np.average(accu),np.average(auc),\n",
    "                       np.average(f1),np.average(aab),np.average(dcd),np.average(tim)]],\n",
    "                     columns=[\"model names\",'CVaccuracy','CVaucroc','CVF1',\"CVsensitivity\",'CVspecificity','CVtime(s)']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv result:\n",
      "[[   98     0]\n",
      " [35985 20879]]\n",
      "cv result:\n",
      "[[   94     4]\n",
      " [25005 31859]]\n",
      "cv result:\n",
      "[[   92     6]\n",
      " [24326 32538]]\n",
      "cv result:\n",
      "[[   93     5]\n",
      " [33946 22918]]\n",
      "cv result:\n",
      "[[   96     2]\n",
      " [33525 23339]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Pipeline([\n",
    "        ('sampling',smp),\n",
    "        ('mlp', MLPClassifier(max_iter=3000))\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "param_grid  = { 'mlp__hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "                'mlp__activation': ['tanh', 'relu'],\n",
    "                'mlp__solver': ['sgd', 'adam'],\n",
    "                'mlp__alpha': [0.0001, 0.05],\n",
    "                'mlp__learning_rate': ['constant','adaptive'],\n",
    "                \n",
    "                }\n",
    "\n",
    "clf = GridSearchCV(model, param_grid, cv = 5, scoring = 'roc_auc',n_jobs=-1)\n",
    "clf.fit(train_data,train_y)\n",
    "bestfit =clf.best_estimator_\n",
    "model_holder.append(bestfit)\n",
    "\"\"\"cv\"\"\"\n",
    "accu,auc,f1,aab,dcd,tim =kfoldtest(5,bestfit,train_data,train_y)\n",
    "cvresult_holder.append(pd.DataFrame([[\"MLP\",np.average(accu),np.average(auc),\n",
    "                       np.average(f1),np.average(aab),np.average(dcd),np.average(tim)]],\n",
    "                     columns=[\"model names\",'CVaccuracy','CVaucroc','CVF1',\"CVsensitivity\",'CVspecificity','CVtime(s)']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv result:\n",
      "[[   95     3]\n",
      " [34364 22500]]\n",
      "cv result:\n",
      "[[   85    13]\n",
      " [19811 37053]]\n",
      "cv result:\n",
      "[[   88    10]\n",
      " [14609 42255]]\n",
      "cv result:\n",
      "[[   86    12]\n",
      " [18275 38589]]\n",
      "cv result:\n",
      "[[   92     6]\n",
      " [30129 26735]]\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"dtc__max_depth\": range(1,20)\n",
    "              , \"dtc__random_state\":[7]}\n",
    "\n",
    "\n",
    "model = Pipeline([\n",
    "        ('sampling', smp),\n",
    "        ('dtc', DecisionTreeClassifier(random_state = 0, \n",
    "                             max_features = \"auto\", class_weight = \"balanced\",\n",
    "                             max_depth = None))\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf = GridSearchCV(model, param_grid, cv = 5, scoring = 'roc_auc',n_jobs=-1)\n",
    "clf.fit(train_data,train_y)\n",
    "bestfit =clf.best_estimator_\n",
    "model_holder.append(bestfit)\n",
    "\"\"\"cv\"\"\"\n",
    "accu,auc,f1,aab,dcd,tim =kfoldtest(5,bestfit,train_data,train_y)\n",
    "cvresult_holder.append(pd.DataFrame([[\"DecisionTree\",np.average(accu),np.average(auc),\n",
    "                       np.average(f1),np.average(aab),np.average(dcd),np.average(tim)]],\n",
    "                     columns=[\"model names\",'CVaccuracy','CVaucroc','CVF1',\"CVsensitivity\",'CVspecificity','CVtime(s)']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv result:\n",
      "[[   98     0]\n",
      " [48144  8720]]\n",
      "cv result:\n",
      "[[   93     5]\n",
      " [22728 34136]]\n",
      "cv result:\n",
      "[[   92     6]\n",
      " [24173 32691]]\n",
      "cv result:\n",
      "[[   93     5]\n",
      " [39426 17438]]\n",
      "cv result:\n",
      "[[   98     0]\n",
      " [38458 18406]]\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"gbc__loss\":[\"deviance\"],\n",
    "    \"gbc__learning_rate\": [0.01,  0.05,  0.1, 0.2],\n",
    "    \"gbc__min_samples_split\": np.linspace(0.1, 0.5, 3),\n",
    "    \"gbc__min_samples_leaf\": np.linspace(0.1, 0.5, 3),\n",
    "    \"gbc__max_depth\":[3,5,8],\n",
    "    \"gbc__max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"gbc__criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"gbc__subsample\":[0.5,  0.8,   1.0],\n",
    "    \"gbc__n_estimators\":[10]\n",
    "    }\n",
    "param_grid = {\n",
    "    \n",
    "    \"gbc__learning_rate\": [0.01,  0.05,  0.1, 0.2],\n",
    "\n",
    "    \"gbc__max_depth\":[3,5,8],\n",
    "\n",
    "    \"gbc__subsample\":[0.5,  0.8,   1.0],\n",
    "    \"gbc__n_estimators\":[10]\n",
    "    }\n",
    "\n",
    "model = Pipeline([\n",
    "        ('sampling',smp),\n",
    "        ('gbc', GradientBoostingClassifier()) ])\n",
    "\n",
    "clf = GridSearchCV(model ,param_grid, cv=5, scoring = 'roc_auc',n_jobs=-1)\n",
    "\n",
    "clf.fit(train_data,train_y)\n",
    "bestfit =clf.best_estimator_\n",
    "model_holder.append(bestfit)\n",
    "\"\"\"cv\"\"\"\n",
    "accu,auc,f1,aab,dcd,tim =kfoldtest(5,bestfit,train_data,train_y)\n",
    "cvresult_holder.append(pd.DataFrame([[\"GradientBoosting\",np.average(accu),np.average(auc),\n",
    "                       np.average(f1),np.average(aab),np.average(dcd),np.average(tim)]],\n",
    "                     columns=[\"model names\",'CVaccuracy','CVaucroc','CVF1',\"CVsensitivity\",'CVspecificity','CVtime(s)']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv result:\n",
      "[[   97     1]\n",
      " [50656  6208]]\n",
      "cv result:\n",
      "[[   91     7]\n",
      " [10212 46652]]\n",
      "cv result:\n",
      "[[   95     3]\n",
      " [27643 29221]]\n",
      "cv result:\n",
      "[[   93     5]\n",
      " [31072 25792]]\n",
      "cv result:\n",
      "[[   95     3]\n",
      " [34556 22308]]\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "    'rfc__n_estimators': [200, 500],\n",
    "\n",
    "    'rfc__max_depth' :(3,5,8,10,20),\n",
    "\n",
    "    }\n",
    "\n",
    "model = Pipeline([\n",
    "        ('sampling', smp),\n",
    "        ('rfc', RandomForestClassifier(random_state=42)) ])\n",
    "\n",
    "clf = GridSearchCV(model,param_grid, cv= 5,scoring = 'roc_auc',n_jobs=-1)\n",
    "clf.fit(train_data,train_y)\n",
    "bestfit =clf.best_estimator_\n",
    "model_holder.append(bestfit)\n",
    "\"\"\"cv\"\"\"\n",
    "accu,auc,f1,aab,dcd,tim =kfoldtest(5,bestfit,train_data,train_y)\n",
    "cvresult_holder.append(pd.DataFrame([[\"RandomForest\",np.average(accu),np.average(auc),\n",
    "                       np.average(f1),np.average(aab),np.average(dcd),np.average(tim)]],\n",
    "                     columns=[\"model names\",'CVaccuracy','CVaucroc','CVF1',\"CVsensitivity\",'CVspecificity','CVtime(s)']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('sampling',\n",
       "                 NearMiss(n_jobs=None, n_neighbors=3, n_neighbors_ver3=3,\n",
       "                          sampling_strategy='auto', version=1)),\n",
       "                ('rfc',\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=3, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=500, n_jobs=None,\n",
       "                                        oob_score=False, random_state=42,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv result:\n",
      "[[   94     4]\n",
      " [46464 10400]]\n",
      "cv result:\n",
      "[[   90     8]\n",
      " [14226 42638]]\n",
      "cv result:\n",
      "[[   91     7]\n",
      " [13573 43291]]\n",
      "cv result:\n",
      "[[   90     8]\n",
      " [12278 44586]]\n",
      "cv result:\n",
      "[[   92     6]\n",
      " [15452 41412]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = LogisticRegression(max_iter=3000,random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "\n",
    "param_grid = { \n",
    "    'rfc__lr__C': np.logspace(-3,3,7), \n",
    "    'rfc__rf__n_estimators': [500],\n",
    "    \n",
    "    'rfc__rf__max_depth' : [20]\n",
    "    }\n",
    "\n",
    "model = Pipeline([\n",
    "        ('sampling', smp),\n",
    "        ('rfc', eclf) ])\n",
    "\n",
    "clf = GridSearchCV(model,param_grid, cv= 5,scoring = 'roc_auc',n_jobs=-1)\n",
    "clf.fit(train_data,train_y)\n",
    "bestfit =clf.best_estimator_\n",
    "model_holder.append(bestfit)\n",
    "\"\"\"cv\"\"\"\n",
    "accu,auc,f1,aab,dcd,tim =kfoldtest(5,bestfit,train_data,train_y)\n",
    "cvresult_holder.append(pd.DataFrame([[\"MajorVoting\",np.average(accu),np.average(auc),\n",
    "                       np.average(f1),np.average(aab),np.average(dcd),np.average(tim)]],\n",
    "                     columns=[\"model names\",'CVaccuracy','CVaucroc','CVF1',\"CVsensitivity\",'CVspecificity','CVtime(s)']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model names</th>\n",
       "      <th>CVaccuracy</th>\n",
       "      <th>CVaucroc</th>\n",
       "      <th>CVF1</th>\n",
       "      <th>CVsensitivity</th>\n",
       "      <th>CVspecificity</th>\n",
       "      <th>CVtime(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.997705</td>\n",
       "      <td>0.901340</td>\n",
       "      <td>0.556792</td>\n",
       "      <td>0.802041</td>\n",
       "      <td>0.998087</td>\n",
       "      <td>1.832592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.462933</td>\n",
       "      <td>0.701890</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>0.965306</td>\n",
       "      <td>0.462623</td>\n",
       "      <td>4.259487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.587189</td>\n",
       "      <td>0.728695</td>\n",
       "      <td>0.007917</td>\n",
       "      <td>0.910204</td>\n",
       "      <td>0.587831</td>\n",
       "      <td>1.808477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.394189</td>\n",
       "      <td>0.667475</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.967347</td>\n",
       "      <td>0.391780</td>\n",
       "      <td>1.858169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.458667</td>\n",
       "      <td>0.694699</td>\n",
       "      <td>0.007677</td>\n",
       "      <td>0.961224</td>\n",
       "      <td>0.457868</td>\n",
       "      <td>4.549060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MajorVoting</td>\n",
       "      <td>0.642827</td>\n",
       "      <td>0.766688</td>\n",
       "      <td>0.010758</td>\n",
       "      <td>0.932653</td>\n",
       "      <td>0.641274</td>\n",
       "      <td>5.533175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model names  CVaccuracy  CVaucroc      CVF1  CVsensitivity  \\\n",
       "0  LogisticRegression    0.997705  0.901340  0.556792       0.802041   \n",
       "0                 MLP    0.462933  0.701890  0.006167       0.965306   \n",
       "0        DecisionTree    0.587189  0.728695  0.007917       0.910204   \n",
       "0    GradientBoosting    0.394189  0.667475  0.005795       0.967347   \n",
       "0        RandomForest    0.458667  0.694699  0.007677       0.961224   \n",
       "0         MajorVoting    0.642827  0.766688  0.010758       0.932653   \n",
       "\n",
       "   CVspecificity  CVtime(s)  \n",
       "0       0.998087   1.832592  \n",
       "0       0.462623   4.259487  \n",
       "0       0.587831   1.808477  \n",
       "0       0.391780   1.858169  \n",
       "0       0.457868   4.549060  \n",
       "0       0.641274   5.533175  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result= pd.concat(cvresult_holder,axis=0)\n",
    "result.to_csv('cvresult_{}sampling.csv'.format(str(samplechoice)))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfpr,tpr,label =testresult(clf,\\'MajorVoting\\',test_data,test_y)\\ntestroc_holder.append([fpr,tpr])\\ntestlabel_holder.append(label)\\n\\n\\nplt.figure(figsize=(11.7,8.27))\\nfor i in range(len(muholder)):\\n    fpr, tpr =testroc_holder[i][0],testroc_holder[i][1]\\n    plt.plot(fpr, tpr,label=testlabel_holder[i])\\n    \\nplt.plot([0,1],[0,1],\"--\",color =\\'r\\')\\nplt.xlabel(\\'1-specificity\\')\\nplt.legend()\\nplt.show()\\nplt.savefig(\\'ruc_curve_{}sampling.csv\\'.format(str(samplechoice)))\\n\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fpr,tpr,label =testresult(clf,'MajorVoting',test_data,test_y)\n",
    "testroc_holder.append([fpr,tpr])\n",
    "testlabel_holder.append(label)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(11.7,8.27))\n",
    "for i in range(len(muholder)):\n",
    "    fpr, tpr =testroc_holder[i][0],testroc_holder[i][1]\n",
    "    plt.plot(fpr, tpr,label=testlabel_holder[i])\n",
    "    \n",
    "plt.plot([0,1],[0,1],\"--\",color ='r')\n",
    "plt.xlabel('1-specificity')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('ruc_curve_{}sampling.csv'.format(str(samplechoice)))\n",
    "\n",
    "\"\"\"\n",
    "#from sklearn.externals import joblib\n",
    "#joblib.dump(grid.best_estimator_, 'filename.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "for i in range(len(model_holder)):\n",
    "    joblib.dump(model_holder[i], 'model{}.pkl'.format(samplechoice+str(i)))\n",
    "    \n",
    "#joblib.load('best_tfidf.pkl') load function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('sampling',\n",
       "                 NearMiss(n_jobs=None, n_neighbors=3, n_neighbors_ver3=3,\n",
       "                          sampling_strategy='auto', version=1)),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=0.001, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=3000,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_holder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
