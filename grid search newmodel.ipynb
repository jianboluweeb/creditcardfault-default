{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['paystate', 'lastpay', 'billpay', 'billlim', 'paylim', 'billchangelim0',\n",
      "       'paychangelim0', 'billchangelim1', 'paychangelim1', 'billchangelim2',\n",
      "       'paychangelim2', 'billchangelim3', 'paychangelim3', 'billchangelim4',\n",
      "       'paychangelim4', 'ageclass_20s', 'ageclass_30s', 'ageclass_40s',\n",
      "       'ageclass_50s', 'ageclass_60s', 'ageclass_70s', 'sex_1', 'sex_2',\n",
      "       'education_0', 'education_1', 'education_2', 'education_3',\n",
      "       'education_4', 'education_5', 'education_6', 'marriage_0', 'marriage_1',\n",
      "       'marriage_2', 'marriage_3', 'default.payment.next.month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=\"pastel\")\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "\n",
    "def stdscaler(df):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df)\n",
    "    scX_df = scaler.transform(df)\n",
    "    df=pd.DataFrame(scX_df, index =df.index,columns =df.columns  )\n",
    "    return df\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "def kfoldtest(kfoldn,model,Xtrain_df,ytrain_df):\n",
    "    kf=StratifiedKFold(n_splits=kfoldn)\n",
    "    accu=[]\n",
    "    auc=[]\n",
    "    f1 =[]\n",
    "    aab =[]\n",
    "    dcd = []\n",
    "    tim = []\n",
    "    kf.get_n_splits(Xtrain_df,ytrain_df)\n",
    "    \n",
    "    for train_index, test_index in kf.split(Xtrain_df,ytrain_df):\n",
    "        #print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "        t1 =time.time()\n",
    "        X_train, X_test = Xtrain_df.iloc[train_index], Xtrain_df.iloc[test_index]\n",
    "        y_train, y_test = ytrain_df.iloc[train_index], ytrain_df.iloc[test_index]\n",
    "        model.fit(X_train,y_train)\n",
    "        try:\n",
    "            accu.append(model.score(X_test,y_test))\n",
    "        except:\n",
    "            print(\"This model have no build-in score.\")\n",
    "            \n",
    "        auc.append(roc_auc_score(y_test,model.predict(X_test)))\n",
    "        f1.append(f1_score(y_test, model.predict(X_test).astype(int),average='binary'))\n",
    "        tim.append(time.time()-t1)\n",
    "        cm1=confusion_matrix(test_y, clf.predict(test_data),labels = [1,0])\n",
    "        sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "        aab.append(sensitivity1)\n",
    "\n",
    "        specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "        dcd.append(specificity1)\n",
    "    return accu,auc,f1,aab,dcd,tim\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "file_name = 'model1.csv'\n",
    "data =pd.read_csv(file_name,index_col = 0)\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = data[data[\"default.payment.next.month\"]==1].copy()\n",
    "v0 = data[data[\"default.payment.next.month\"]==0].copy()\n",
    "v1.rename(columns={\"default.payment.next.month\": \"default\"},inplace = True)\n",
    "v0.rename(columns={\"default.payment.next.month\": \"default\"},inplace = True)\n",
    "y1 = v1[\"default\"].copy()\n",
    "x1 = v1.copy()\n",
    "del x1[\"default\"]\n",
    "y0 = v0[\"default\"].copy()\n",
    "x0 = v0.copy()\n",
    "del x0[\"default\"]\n",
    "\n",
    "tr1,te1,try1,tey1 = train_test_split(\n",
    "    x1, y1, test_size=0.20, random_state=42)\n",
    "tr2,te2,try2,tey2 = train_test_split(\n",
    "    x0, y0, test_size=0.20, random_state=42)\n",
    "####\n",
    "#tr2=tr2.sample(len(tr1.index))\n",
    "\n",
    "#try2 = try2.loc[tr2.index].copy()\n",
    "####\n",
    "\n",
    "\n",
    "train_data=pd.concat([tr1,tr2],axis=0)\n",
    "\n",
    "train_y = pd.concat([try1,try2],axis=0)\n",
    "test_data=pd.concat([te1,te2],axis=0)\n",
    "\n",
    "test_y = pd.concat([tey1,tey2],axis=0)\n",
    "\n",
    "\n",
    "train_data = stdscaler(train_data )\n",
    "test_data = stdscaler(test_data )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pca =PCA(n_components=.99).fit(train_data)\\ntrain_data = pd.DataFrame(pca.transform(train_data),index = train_data.index)   \\n\\ntest_data= pd.DataFrame(pca.transform(test_data),index = test_data.index)  \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"pca =PCA(n_components=.99).fit(train_data)\n",
    "train_data = pd.DataFrame(pca.transform(train_data),index = train_data.index)   \n",
    "\n",
    "test_data= pd.DataFrame(pca.transform(test_data),index = test_data.index)  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='tanh', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(50, 100, 50), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=3000,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n",
      "CV accuarcy: 0.7603952171904297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.38      0.47      1264\n",
      "           0       0.84      0.93      0.89      4563\n",
      "\n",
      "    accuracy                           0.81      5827\n",
      "   macro avg       0.73      0.66      0.68      5827\n",
      "weighted avg       0.80      0.81      0.80      5827\n",
      "\n",
      "GSC area=0.65\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid  = { 'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "                'activation': ['tanh', 'relu'],\n",
    "                'solver': ['sgd', 'adam'],\n",
    "                'alpha': [0.0001, 0.05],\n",
    "                'learning_rate': ['constant','adaptive'],\n",
    "               \n",
    "                }\n",
    "\n",
    "clf = GridSearchCV(MLPClassifier(max_iter=3000), param_grid, cv = 5, scoring = 'roc_auc',n_jobs=-1)\n",
    "\n",
    "\n",
    "clf.fit(train_data,train_y)\n",
    "#let's see the best estimator\n",
    "print(clf.best_estimator_)\n",
    "#with its score\n",
    "print('CV accuarcy:',np.abs(clf.best_score_))\n",
    "print(classification_report(test_y, clf.predict(test_data), labels=[1,0]))\n",
    "print(''.join([c for c in str(clf) if c.isupper()])[:3]+' area='+str(roc_auc_score(test_y, clf.predict(test_data)))[:4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
      "                                                         class_weight='balanced',\n",
      "                                                         criterion='entropy',\n",
      "                                                         max_depth=None,\n",
      "                                                         max_features='auto',\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         presort='deprecated',\n",
      "                                                         random_state=0,\n",
      "                                                         splitter='best'),\n",
      "                   learning_rate=1.0, n_estimators=20, random_state=None)\n",
      "CV accuarcy: 0.6683241426414874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.40      0.40      1264\n",
      "           0       0.83      0.84      0.83      4563\n",
      "\n",
      "    accuracy                           0.74      5827\n",
      "   macro avg       0.62      0.62      0.62      5827\n",
      "weighted avg       0.74      0.74      0.74      5827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "              \"n_estimators\": [5,10,20]\n",
    "             }\n",
    "\n",
    "\n",
    "DTC = DecisionTreeClassifier(random_state = 0, \n",
    "                             max_features = \"auto\", class_weight = \"balanced\",\n",
    "                             max_depth = None)\n",
    "\n",
    "ABC = AdaBoostClassifier(base_estimator = DTC)\n",
    "\n",
    "# run grid search\n",
    "grid_search_ABC = GridSearchCV(ABC, param_grid=param_grid,cv = 5, scoring = 'roc_auc',n_jobs=-1)\n",
    "\n",
    "grid_search_ABC.fit(train_data,train_y)\n",
    "#let's see the best estimator\n",
    "print(grid_search_ABC.best_estimator_)\n",
    "#with its score\n",
    "print('CV accuarcy:',np.abs(grid_search_ABC.best_score_))\n",
    "print(classification_report(test_y, grid_search_ABC.predict(test_data), labels=[1,0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.15,0.2 ],\n",
    "    \"min_samples_split\": [0.1,0,25,0.5],\n",
    "    \"min_samples_leaf\": [0.1,0.25,0.5],\n",
    "    \"max_depth\":[3,5,8,10],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 1.0],\n",
    "    \"n_estimators\":[10]\n",
    "    }\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), parameters, cv=5, scoring = 'roc_auc',n_jobs=-1)\n",
    "\n",
    "clf.fit(train_data,train_y)\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_params_)\n",
    "print('CV accuarcy:',np.abs(clf.best_score_))\n",
    "print(classification_report(test_y, clf.predict(test_data), labels=[1,0]))\n",
    "print(''.join([c for c in str(clf) if c.isupper()])[:3]+' area='+str(roc_auc_score(test_y, clf.predict(test_data)))[:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=10, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "CV accuarcy: 0.7743908334671861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.21      0.32      1264\n",
      "           0       0.82      0.97      0.89      4563\n",
      "\n",
      "    accuracy                           0.81      5827\n",
      "   macro avg       0.74      0.59      0.60      5827\n",
      "weighted avg       0.78      0.81      0.76      5827\n",
      "\n",
      "GSC area=0.58\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [10,50,100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [5,8,10,50],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(random_state=42),param_grid, cv= 5,scoring = 'roc_auc',n_jobs=-1)\n",
    "clf.fit(train_data,train_y)\n",
    "print(clf.best_estimator_)\n",
    "#with its score\n",
    "print('CV accuarcy:',np.abs(clf.best_score_))\n",
    "print(classification_report(test_y, clf.predict(test_data), labels=[1,0]))\n",
    "print(''.join([c for c in str(clf) if c.isupper()])[:3]+' area='+str(roc_auc_score(test_y, clf.predict(test_data)))[:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
